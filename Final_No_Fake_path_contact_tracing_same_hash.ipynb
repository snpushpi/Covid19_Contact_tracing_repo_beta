{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_No_Fake_path_contact_tracing_same_hash.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMs8p7K+v/2/C9dXM/2IkLA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHfygvdbI-fH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import hashlib\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVce01EsR8Kw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h3-iPW1SEIl",
        "colab_type": "text"
      },
      "source": [
        "create a dataframe object from the csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snLRXWXySLbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_dataframe = pd.read_csv(r\"C:\\Users\\pushp\\Downloads\\Geolife-Trajectories-1.3\\Geolife-Trajectories-1.3\\Modified_Final_Dataset.csv\")\n",
        "new_dataframe.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByS_BGdxSXlA",
        "colab_type": "text"
      },
      "source": [
        "Next few parts, we will be making our data in a usable format for feeding into our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z08m0TEYScfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def list_generate(new_dataframe,user_num):    \n",
        "    user_lat = new_dataframe[new_dataframe.User_ID==user_num]['Modified_Latitude'].to_list()\n",
        "    user_lon = new_dataframe[new_dataframe.User_ID==user_num]['Modified_Longitude'].to_list()\n",
        "    user_timestamp = new_dataframe[new_dataframe.User_ID==user_num]['Timestamp'].to_list()\n",
        "    l = len(new_dataframe[new_dataframe.user_num==57])\n",
        "    user_path = [(querier_lat[i], querier_lon[i], querier_timestamp[i]) for i in range(l)]\n",
        "    return user_path\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWWfREAuSpRN",
        "colab_type": "text"
      },
      "source": [
        "For 50 infected users, we will create a list of lists where each list is the path of one infected patient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQBXeT6TSqm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "querier_path = list_generate(new_dataframe,57)\n",
        "infected_list = []\n",
        "infected1 = list_generate(new_dataframe,94)\n",
        "infected2 = list_generate(new_dataframe,150)\n",
        "infected_list.append(infected1)\n",
        "infected_list.append(infected2)\n",
        "for i in range(50):\n",
        "    infected_list.append(list_generate(new_dataframe,i))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcAWCqqetBOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def position_determiner(lat, lon):\n",
        "    '''Given a latitude, longitude co-ordinate, we have to find the small universe it belongs to.'''\n",
        "    min_lat = 23.4377\n",
        "    max_lat = 40.9999\n",
        "    min_lon = 113.7947\n",
        "    max_lon = 117.1832\n",
        "    k = math.floor((lat-min_lat)/0.0030)\n",
        "    j = math.floor((lat-min_lon)/0.0030)\n",
        "    return (k,j)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12vytdzgt6EX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def path_divider(path):\n",
        "    '''given a path (a list of tuples, (lat, lon, timestamp)), divides it into zones.\n",
        "    returns: a dictionary zone->[{timestamp->(lat,lon, timestamp)},[timestamp_list]]'''\n",
        "    track_dict = {}\n",
        "    for elt in path:\n",
        "        temp_val = position_determiner(elt[0], elt[1])\n",
        "        if temp_val not in track_dict:\n",
        "            track_dict[temp_val]=[{},[]]\n",
        "            track_dict[temp_val][0][elt[2]]= elt\n",
        "            track_dict[temp_val][1].append(elt[2])\n",
        "        else:\n",
        "            track_dict[temp_val][0][elt[2]]= elt\n",
        "            track_dict[temp_val][1].append(elt[2])\n",
        "    return track_dict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYq_lPwJK60R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Querier():\n",
        "    def __init__(self,true_path):\n",
        "        self.true_path = true_path\n",
        "        self.filtered_dictionary = {}\n",
        "        self.intersection = []\n",
        "\n",
        "    def filter_divider(self):\n",
        "        '''returns zone->timestamp_list dictionary.'''\n",
        "        self.filtered_dictionary = path_divider(self.true_path)     \n",
        "        filt_dict = {e:self.filtered_dictionary[e][1] for e in self.filtered_dictionary}\n",
        "        return filt_dict\n",
        "\n",
        "    def checker(self, freq_dict, zone):\n",
        "        '''given the dictionary, checks the intersection with its elements, in other words, for each of its elements in this zone,\n",
        "        it checks whether the frequency in the dictionary is greater than 1.'''\n",
        "        timestamp_list = self.filtered_dictionary[zone][1]\n",
        "        new_all_list = [zone+(timestamp,) for timestamp in timestamp_list]\n",
        "        for elt in new_all_list:\n",
        "            if freq_dict[elt]>=1:\n",
        "                self.intersection.append(elt)\n",
        "                \n",
        "    def annoncer(self):\n",
        "        '''returns the self.intersection list.'''\n",
        "        return self.intersection\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-lTaI8BD-dX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Infected():\n",
        "    def __init__(self, true_path,width, depth,epsilon,seed):\n",
        "        self.width = width\n",
        "        self.depth = depth\n",
        "        self.epsilon = epsilon\n",
        "        self.seed = seed\n",
        "        self.true_path = true_path\n",
        "        self.filtered_dictionary = {}\n",
        "        self.new_level2_filter = {}\n",
        "    #Implementing the client side algorithm which works on each particular data element. First it selects an integer randomly from 0 to depth-1, \n",
        "    #we store that value as j, next, we initialize a vector of -1, of length width, and set that jth index as 1. Then we create another vector of -1s\n",
        "    #and +1s, with fixed probabilities determined by the parameter epsilon. Then we do element wise multioplication and return the \n",
        "    #result vector. \n",
        "\n",
        "    def Client_Side(self,d):\n",
        "        '''parameters are a data element, epsilon value and a hash family, but we are using mmh3 here so didn't add that as a parameter'''\n",
        "        j = np.random.randint(self.depth) \n",
        "        z_vect = np.zeros((1,self.width))\n",
        "        v = z_vect-1 \n",
        "        hex_num = hashlib.sha256((str(self.seed[j])+str(d)).encode('utf-8')).hexdigest()\n",
        "        int_hex = int(hex_num[:5],16)\n",
        "        index = int_hex % self.width\n",
        "        v[0,index]=1\n",
        "        val = np.exp(self.epsilon/2)\n",
        "        probability_of_1 = val/(val+1) \n",
        "        probability_of_neg_1 = 1/(val+1)\n",
        "        b = np.random.choice([1,-1],self.width,p=[probability_of_1,probability_of_neg_1]) \n",
        "        final_vector = v*b\n",
        "        return (final_vector,j) \n",
        "\n",
        "    def send_flipped_bit_vector(self,zone):\n",
        "        result_list = []\n",
        "        for elt in self.new_level2_filter[zone]:\n",
        "            result_list.append(self.Client_Side(elt))\n",
        "        return result_list\n",
        "\n",
        "    def filter_divider(self):\n",
        "        '''returns: zone->timestamp_list.'''\n",
        "        self.filtered_dictionary = path_divider(self.true_path)\n",
        "        filt_dict = {e:self.filtered_dictionary[e][1] for e in self.filtered_dictionary}\n",
        "        return filt_dict\n",
        "        \n",
        "    def filter2(self,filtered_dict_from_server):\n",
        "        '''filtered_dict_from_server, a dictionary with zone->timestamps.\n",
        "        modifies: a new_level2_filter list, and new_level2_filter_list[zone] is a list of (lat, lon, timestamp).'''\n",
        "        for zone in filtered_dict_from_server:\n",
        "            self.new_level2_filter[zone]=[]\n",
        "            for elt in filtered_dict_from_server[zone]:\n",
        "                self.new_level2_filter[zone].append(self.filtered_dictionary[zone][0][elt])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TK80cumIIdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Server():\n",
        "    def __init__(self, width, depth, epsilon, seed):\n",
        "        self.width = width\n",
        "        self.depth = depth\n",
        "        self.epsilon = epsilon\n",
        "        self.seed = seed \n",
        "        self.zone_list=[]\n",
        "        self.new_filtered_list = []\n",
        "\n",
        "    def Compute_Sketch_Matrix(self,D):\n",
        "        '''So each element of D is a tuple where the first element is v_i and second element is j_i(which is created by the above funstion after getting \n",
        "        passed by Client_side each time), we have privacy parameter epsilon and dimensions. v_i is the a vector an it has the sma eshape as the \n",
        "        vectors returned by the Client_side algorithm'''\n",
        "        val = np.exp(self.epsilon/2)\n",
        "        n = len(D)\n",
        "        c_epsilon = (val+1)/(val-1) \n",
        "        vec_one = np.ones((1,self.width))\n",
        "        manipulated_data_matrix = np.zeros((n,self.width)) #Creatimg a matrix for x_is\n",
        "        for elt in enumerate(D):\n",
        "            new_vect = elt[1][0].reshape((1,self.width))\n",
        "            man_vect = (c_epsilon/2)*new_vect #scalar and vector multiplication \n",
        "            half_vec_one = 0.5*vec_one \n",
        "            sum_vect = man_vect + half_vec_one\n",
        "            manipulated_data_matrix[[elt[0]],:]= self.depth*sum_vect  \n",
        "        M = np.zeros((self.depth,self.width))\n",
        "        for elt in enumerate(D):\n",
        "            for l in range(self.width): \n",
        "                M[elt[1][1],l]=M[elt[1][1],l]+manipulated_data_matrix[elt[0],l]\n",
        "        return M \n",
        "\n",
        "    def frequency_counter(self, Sketch_Matrix, total_path_length, universe_list):\n",
        "        ''' we get a sketch matrix and we try to get the frequencies for all elements in the true_path.'''\n",
        "        frequency_dict = {}\n",
        "        for d in universe_list:\n",
        "            n = total_path_length\n",
        "            frac1 = self.width/(self.width-1)\n",
        "            frac2 = n/self.width\n",
        "            row_sum = 0\n",
        "            for i in range(self.depth):\n",
        "                hex_num = hashlib.sha256((str(self.seed[i])+str(d)).encode('utf-8')).hexdigest()\n",
        "                int_hex = int(hex_num[:5],16)\n",
        "                index = int_hex % self.width\n",
        "                row_sum = row_sum + Sketch_Matrix[i,index]\n",
        "            avg_row_sum = row_sum/self.depth \n",
        "            subtraction = avg_row_sum - frac2 \n",
        "            assumed_freq = frac1*subtraction \n",
        "            frequency_dict[d]=assumed_freq\n",
        "        return frequency_dict\n",
        "\n",
        "    def checker(self,querier_filtered_path, infected_patients_filtered_dict_list):\n",
        "        '''gets zone-> timestamps and returns list of filtered zone-> set(timestamps) dictionaries.'''\n",
        "        l = len(infected_patients_filtered_dict_list)\n",
        "        for i in range(l):\n",
        "            temp_dict={}\n",
        "            for zone in infected_patients_filtered_dict_list[i]:\n",
        "                if zone in querier_filtered_path:\n",
        "                    temp_dict[zone] = set(infected_patients_filtered_dict_list[zone]) & set(querier_filtered_path[zone])\n",
        "            self.new_filtered_list.append(temp_dict)#For all infected patients, it maintains a dictionary, mapping zone to timestamps.\n",
        "        return self.new_filtered_list\n",
        "    \n",
        "    def universe_generate(self, zone, timestamp_list):\n",
        "        '''generate the universe list with the timestamps.'''\n",
        "        lat = zone[0]\n",
        "        lon = zone[1]\n",
        "        lat_list = []\n",
        "        lon_list = []\n",
        "        universe_list = []\n",
        "        for i in np.arange(lat, lat+0.0031, 0.0001):\n",
        "            for j in np.arange(lon, lon+0.0031, 0.0001):\n",
        "                for time in timestamp_list:\n",
        "                    universe_list.append((i, j, time))\n",
        "        return universe_list\n",
        "\n",
        "    def bit_flip_caller(self, infected_patients, querier):\n",
        "        '''Will call the flip bit method on all zones of each infected patient.'''\n",
        "        l = len(self.new_filtered_list)\n",
        "        for i in range(l):\n",
        "            for zone in self.new_filtered_list[i]:\n",
        "                sketch_matrix = np.zeros((self.width,self.depth))\n",
        "                for i in range(800):#run number, for doing average \n",
        "                    D = infected_patients[i].send_bit_flipped_vector(zone)\n",
        "                    M = self.compute_sketch_matrix(D)\n",
        "                    for row in range(self.depth):\n",
        "                        for col in range(self.width):\n",
        "                            sketch_matrix[row, col] = (i*sketch_matrix[row, col]+M[row, col])/(i+1)\n",
        "                #now we will calculate the frequency \n",
        "                universe_list = self.universe_generate(zone, self.new_filtered_list[i][zone])\n",
        "                #finally count the frequency for each element in this universe list\n",
        "                n = len(self.new_filtered_list[i][zone])\n",
        "                freq_dict = frequency_counter(sketch_matrix,l, universe_list)\n",
        "                querier.checker(freq_dict,zone)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_7Bu1hNGFCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#in the new mode, we invoke this method and the server receives this flipped bit vectors, as we want to average the \n",
        "#bit flipping thing, we run this process a mentioned number of times. and make compute sketch matrix."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFhh-DbKK7Wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def driver_code(width, depth, seed, epsilon, run_number):\n",
        "    '''1. Create instances of querier, server and infected patients.\n",
        "       2. Call the filter method on all the participants in the server, so all the querier and the infectd patients filter out their paths \n",
        "          in multiple universes. This function will output a dictionary kepys mapping to 2 lists, one list is the co-ordinates in that universe and another list is the timestamp.\n",
        "       3. Now send this filtered timestamp and zone list to the server. Form can be (zone code->timestamps in that zone)\n",
        "       4. Taking the querier's timestamp against the infected patient's timestamp, server will level2 filtering and send similar form of \n",
        "          dictionary to all the infected patients and the querier, so basically finding the timestamp intersection between querier and infected patient pair\n",
        "          and server is keeping the lists for his calculation.\n",
        "       5. The participants, upon receiving the information, filters out the information further and start processing data from their end, aka, \n",
        "          calls the server caller method.(So in our implementation, we will be processing all infected patients one by one)\n",
        "       6. The server caller method, is a common method which will be used in other parts too, when this method is called from some \n",
        "          infected patient, it asks for flipped vectors a mentioned number of times from the infected patient and upon receiving it every time,\n",
        "          the server does the compute sketch matrix operation and contnues averaging it and finally gets the aggregated sketch matrix, as the server knows which \n",
        "          infected patient and from which zone, it was being called, he finally calls freq generator with this information.(Zone code, sketch matrix and server has saved the timestamp info\n",
        "          for generating universe list)\n",
        "       7. Thus for each caller method, server keeps generating frequency histogram and keeps aggregating it and will finally send it to the querier \n",
        "       \n",
        "    '''\n",
        "    querier = Querier(querier_path)\n",
        "    infected_patients = []\n",
        "    for infected in infected_list:\n",
        "        infected_patients.append(Infected(infected, width, depth, epsilon, seed))\n",
        "    server_instance = Server(width, depth, epsilon, seed)\n",
        "    infected_patients_filtered_dict_list=[]\n",
        "    for e in infected_patients:\n",
        "        infected_patients_filtered_dict_list.append(e.filter_divider())\n",
        "    querier_filter = querier.filter_divider()\n",
        "    new_filtered_list = server_instance.checker(queier_filter, infected_patients_filtered_dict_list)\n",
        "    l = len(new_filtered_list)\n",
        "    for i in range(l):\n",
        "        infected_patients[i].filter2(new_filtered_list[i])\n",
        "    server_instance.bit_filp_caller()\n",
        "    return querier.announcer()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0bxpGd3HIRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = [172,  55, 177, 191, 199,  23,  82, 126,  83,  21,   6,  69, 122,\n",
        "        95,  81, 194,  80,  87, 188, 159, 107,  66,   3,  38,  52,  32,\n",
        "       140,  44, 185,  20, 154,  36, 186,  99, 149, 100,  53,  58,  96,\n",
        "       160, 108,  46, 150, 179,   2, 142, 151,  76,  65,  72,  59, 129,\n",
        "        51,  11, 193,  79, 105,  42,  77, 104,  25, 189,  35, 125,  61,\n",
        "       164, 112, 190, 106,  29,  27,  33,   9, 184,  91,  26,  93, 130,\n",
        "        39, 187, 174,  88, 178, 168,  63, 198, 169, 157,  10, 111, 196,\n",
        "        73,  12, 115,  78, 162,  64, 147,  54, 103]\n",
        "width = 150\n",
        "depth = 100\n",
        "epsilon = 4.5\n",
        "driver_code(width, depth, epsilon, seed)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}