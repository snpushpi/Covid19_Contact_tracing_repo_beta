{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence_fragment_puzzle_DP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNRuQElYBQo3NA/AYW1EL36"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNtzhVmzjR-q",
        "colab_type": "text"
      },
      "source": [
        "We are finally using the SFP algorithm in order to avoid the use of a universe list with all possible elements which creates a lot of false signals. It uses all the algorithms from the previous version, in addition, it uses SFP version on the top of the previous algorithms to give the really most frequent words, instead of a lot of fake counts.Unlike Apple's case, we will kinda maintain length 5 strings and will pad chars if not full."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erJdMWMAmfg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import hashlib\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlqMfrBnnWoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Differential_Privacy_CMS_with_SFP():\n",
        "    def __init__(self, width, depth, epsilon, max_coor=None):\n",
        "        self.width = width\n",
        "        self.depth = depth\n",
        "        self.epsilon = epsilon\n",
        "        self.seed = np.random.choice(np.arange(0,self.width),replace=False,size=self.depth) if width!=None else None\n",
        "        self.max = max_coor\n",
        "    def CLient_Side(self,d):\n",
        "        '''parameters are a data element, epsilon value and a hash family, but we are using mmh3 here so didn't add that as a parameter'''\n",
        "        d = d[0]*self.max+d[1]\n",
        "        j = np.random.randint(self.depth) \n",
        "        z_vect = np.zeros((1,self.width))\n",
        "        v = z_vect-1 \n",
        "        hex_num = hashlib.sha256((str(self.seed[j])+str(d)).encode('utf-8')).hexdigest()\n",
        "        int_hex = int(hex_num[:5],16)\n",
        "        index = int_hex % self.width\n",
        "        v[0,index]=1\n",
        "        val = np.exp(self.epsilon/2)\n",
        "        probability_of_1 = val/(val+1) \n",
        "        probability_of_neg_1 = 1/(val+1)\n",
        "        b = np.random.choice([1,-1],self.width,p=[probability_of_1,probability_of_neg_1]) \n",
        "        final_vector = v*b\n",
        "        return (final_vector,j)\n",
        "        \n",
        "    def Compute_Sketch_Matrix(self,D):\n",
        "        '''So each element of D is a tuple where the first element is v_i and second element is j_i(which is created by the above funstion after getting \n",
        "        passed by Client_side each time), we have privacy parameter epsilon and dimensions. v_i is the a vector an it has the sma eshape as the \n",
        "        vectors returned by the Client_side algorithm'''\n",
        "        val = np.exp(self.epsilon/2)\n",
        "        n = len(D)\n",
        "        c_epsilon = (val+1)/(val-1) \n",
        "        vec_one = np.ones((1,self.width))\n",
        "        manipulated_data_matrix = np.zeros((n,self.width)) #Creatimg a matrix for x_is\n",
        "        for elt in enumerate(D):\n",
        "            new_vect = elt[1][0].reshape((1,self.width))\n",
        "            man_vect = (c_epsilon/2)*new_vect #scalar and vector multiplication \n",
        "            half_vec_one = 0.5*vec_one \n",
        "            sum_vect = man_vect + half_vec_one\n",
        "            manipulated_data_matrix[[elt[0]],:]= self.depth*sum_vect  \n",
        "        M = np.zeros((self.depth,self.width))\n",
        "        for elt in enumerate(D):\n",
        "            for l in range(self.width): \n",
        "                M[elt[1][1],l]=M[elt[1][1],l]+manipulated_data_matrix[elt[0],l]\n",
        "        return M \n",
        "        \n",
        "    def Server_Side(self,Sketch_Matrix,d,length):\n",
        "        '''It returns the estimated frequency of a data element given to it. So it has two parameters, data element and the length of the \n",
        "        data stream we are considering'''\n",
        "        d=d[0]*self.max+d[1]\n",
        "        n = length \n",
        "        frac1 = self.width/(self.width-1)\n",
        "        frac2 = n/self.width\n",
        "        row_sum = 0\n",
        "        for i in range(self.depth):\n",
        "            hex_num = hashlib.sha256((str(self.seed[i])+str(d)).encode('utf-8')).hexdigest()\n",
        "            int_hex = int(hex_num[:5],16)\n",
        "            index = int_hex % self.width\n",
        "            row_sum = row_sum + Sketch_Matrix[i,index]\n",
        "        avg_row_sum = row_sum/self.depth \n",
        "        subtraction = avg_row_sum - frac2 \n",
        "        assumed_freq = frac1*subtraction \n",
        "        return assumed_freq\n",
        "\n",
        "    def Count_Mean_Sketch(self,D_s,D,hash_eps_indicator): \n",
        "        '''D_s is the stream of data and this is a subset of universe of data'''\n",
        "        Modified_datalist = []\n",
        "        Sketch_Matrix = []\n",
        "        freq_vect = {}\n",
        "        length = len(D_s) \n",
        "        for elt in enumerate(D_s):\n",
        "            Modified_datalist.append(self.CLient_Side(elt[1])) \n",
        "        Sketch_Matrix = self.Compute_Sketch_Matrix(Modified_datalist)\n",
        "        for d in D:\n",
        "            freq_vect[d] = self.Server_Side(Sketch_Matrix,d,length) \n",
        "        return freq_vect\n",
        "\n",
        "    def frequency_counter_on_average(self,path_list):\n",
        "        '''This function runs the entire process multiple and take the running average of frequencies for reducing error'''\n",
        "        u_list = [(x,y) for x in range(20) for y in range(80)]\n",
        "        freq_counter_cum = {d:0 for d in u_list}\n",
        "        for i in range(500):\n",
        "            freq_counter_new = self.Count_Mean_Sketch(path_list, u_list)\n",
        "            for d in freq_counter_new:\n",
        "                freq_counter_cum[d]=(i*freq_counter_cum[d]+freq_counter_new[d])/(i+1)\n",
        "        return freq_counter_cum\n",
        "\n",
        "def Client_SFP(d):\n",
        "    '''d is a tuple in our example, so for converting it to a string, we are doing this d[0]*self.max+d[1] and then make it a string.'''\n",
        "    l = np.random.randint(2)\n",
        "    d =  str(d[0]*self.max+d[1])\n",
        "    if len(d)<4:\n",
        "        pad = 4-len(d)\n",
        "        for i in range(pad):\n",
        "            d+='0'\n",
        "    output256 = hashlib.sha256(d.encode('utf-8')).hexdigest()#h(s)\n",
        "    r = output256 + d[2*l:2*l+2]\n",
        "    return (self.CLient_Side(r,'0'), self.Client_side(d,'main'),l)\n",
        "def splitter(string):\n",
        "    '''getting a string, it splits it into two parts, second part contains the last two characters.'''\n",
        "\n",
        " \n",
        "def Server_SFP(server_elt_set,CMS_class_main,CMS_class_not,T):\n",
        "    '''For all data elements client SFP creates a tuple of length 3 and call server SFP on all those elements.So D ois the set of all those tuples.'''\n",
        "    beta_data = []\n",
        "    for elt in server_elt_set:\n",
        "        beta_data.append(elt[1])\n",
        "    M = CMS_class_main.frequency_counter_on_average(beta_data)\n",
        "    alpha_list1=[]\n",
        "    alpha_list2=[]\n",
        "    for elt in server_elt_set:\n",
        "        if elt[2]==0:\n",
        "            alpha_list1.append(elt[0])\n",
        "        else:\n",
        "            alpha_list2.append(elt[0])\n",
        "    M1 = CMS_class_not.frequency_counter_on_average(alpha_list1)#frequency histogram\n",
        "    M2 = CMS_class_not.frequency_counter_on_average(alpha_list2)#frequency histogram\n",
        "    Q1=set(dict(sorted(M1.items(), key = itemgetter(1), reverse =True)[:T]).keys())\n",
        "    Q2=set(dict(sorted(M2.items(), key = itemgetter(1), reverse =True)[:T]).keys())\n",
        "    Q1_dict={}\n",
        "    Q2_dict={}\n",
        "    for elt in Q1:\n",
        "        word,val = splitter(elt)\n",
        "        Q1_dict[word]=val\n",
        "    for elt in Q2:\n",
        "        word,val=splitter(elt)\n",
        "        Q2_dict[word]=val\n",
        "    #will find the intersection of Q1 and Q2\n",
        "    new_string_set = set()\n",
        "    for word in Q1_dict:\n",
        "        if word in Q2_dict:\n",
        "            add_string = Q1_dict[word]+Q2_dict[word]\n",
        "            new_string_set.add(add_string)\n",
        "    final_freq_dict ={}\n",
        "    for elt in new_string_set:\n",
        "        final_freq_dict[elt]=M[elt]\n",
        "    return final_freq_dict\n",
        "    \n",
        "def Sequence_Fragment_Puzzle(D_s,D,T):\n",
        "    '''Main driver code of sequence fragment puzzle.'''\n",
        "    CMS_class_main = Differential_Privacy_CMS_with_SFP(100,100,5,90)\n",
        "    CMS_class_not = Differential_Privacy_CMS_with_SFP(100,100,5,90)\n",
        "    T = 100 #threshold value, the maximum number \n",
        "    server_elt_set = set()\n",
        "    for d in D_s:\n",
        "        server_elt_set.add(Client_SFP(d))\n",
        "    return Server_SFP(server_elt_set,CMS_class_main,CMS_class_not,T)\n"
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}