{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence_fragment_puzzle_DP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPiiTAtqDw0qvZ2aFvjSW+I"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNtzhVmzjR-q",
        "colab_type": "text"
      },
      "source": [
        "We are finally using the SFP algorithm in order to avoid the use of a universe list with all possible elements which creates a lot of false signals. It uses all the algorithms from the previous version, in addition, it uses SFP version on the top of the previous algorithms to give the really most frequent words, instead of a lot of fake counts.Unlike Apple's case, we will kinda maintain length 5 strings and will pad chars if not full."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erJdMWMAmfg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import hashlib\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random\n",
        "from collections import Counter\n",
        "from operator import itemgetter"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlqMfrBnnWoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Differential_Privacy_CMS_with_SFP():\n",
        "    def __init__(self, width, depth, epsilon, max_coor=None):\n",
        "        self.width = width\n",
        "        self.depth = depth\n",
        "        self.epsilon = epsilon\n",
        "        self.seed = np.random.choice(np.arange(0,self.width),replace=False,size=self.depth) if width!=None else None\n",
        "        self.max = max_coor\n",
        "\n",
        "    def Client_Side(self,d):\n",
        "        '''parameters are a data element, epsilon value and a hash family, but we are using mmh3 here so didn't add that as a parameter'''\n",
        "        j = np.random.randint(self.depth) \n",
        "        z_vect = np.zeros((1,self.width))\n",
        "        v = z_vect-1 \n",
        "        hex_num = hashlib.sha256((str(self.seed[j])+str(d)).encode('utf-8')).hexdigest()\n",
        "        int_hex = int(hex_num[:5],16)\n",
        "        index = int_hex % self.width\n",
        "        v[0,index]=1\n",
        "        val = np.exp(self.epsilon/2)\n",
        "        probability_of_1 = val/(val+1) \n",
        "        probability_of_neg_1 = 1/(val+1)\n",
        "        b = np.random.choice([1,-1],self.width,p=[probability_of_1,probability_of_neg_1]) \n",
        "        final_vector = v*b\n",
        "        return (final_vector,j)\n",
        "        \n",
        "    def Compute_Sketch_Matrix(self,D):\n",
        "        '''So each element of D is a tuple where the first element is v_i and second element is j_i(which is created by the above funstion after getting \n",
        "        passed by Client_side each time), we have privacy parameter epsilon and dimensions. v_i is the a vector an it has the sma eshape as the \n",
        "        vectors returned by the Client_side algorithm'''\n",
        "        val = np.exp(self.epsilon/2)\n",
        "        n = len(D)\n",
        "        c_epsilon = (val+1)/(val-1) \n",
        "        vec_one = np.ones((1,self.width))\n",
        "        manipulated_data_matrix = np.zeros((n,self.width)) #Creatimg a matrix for x_is\n",
        "        for elt in enumerate(D):\n",
        "            new_vect = elt[1][0].reshape((1,self.width))\n",
        "            man_vect = (c_epsilon/2)*new_vect #scalar and vector multiplication \n",
        "            half_vec_one = 0.5*vec_one \n",
        "            sum_vect = man_vect + half_vec_one\n",
        "            manipulated_data_matrix[[elt[0]],:]= self.depth*sum_vect  \n",
        "        M = np.zeros((self.depth,self.width))\n",
        "        for elt in enumerate(D):\n",
        "            for l in range(self.width): \n",
        "                M[elt[1][1],l]=M[elt[1][1],l]+manipulated_data_matrix[elt[0],l]\n",
        "        return M \n",
        "        \n",
        "    def Server_Side(self,Sketch_Matrix,d,length):\n",
        "        '''It returns the estimated frequency of a data element given to it. So it has two parameters, data element and the length of the \n",
        "        data stream we are considering'''\n",
        "        n = length \n",
        "        frac1 = self.width/(self.width-1)\n",
        "        frac2 = n/self.width\n",
        "        row_sum = 0\n",
        "        for i in range(self.depth):\n",
        "            hex_num = hashlib.sha256((str(self.seed[i])+str(d)).encode('utf-8')).hexdigest()\n",
        "            int_hex = int(hex_num[:5],16)\n",
        "            index = int_hex % self.width\n",
        "            row_sum = row_sum + Sketch_Matrix[i,index]\n",
        "        avg_row_sum = row_sum/self.depth \n",
        "        subtraction = avg_row_sum - frac2 \n",
        "        assumed_freq = frac1*subtraction \n",
        "        return assumed_freq\n",
        "\n",
        "    def Count_Mean_Sketch(self,client_side_result_list,Universe_list): \n",
        "        '''D_s is the stream of data and this is a subset of universe of data'''\n",
        "        Sketch_Matrix = []\n",
        "        freq_vect = {}\n",
        "        length = len(client_side_result_list) \n",
        "        Sketch_Matrix = self.Compute_Sketch_Matrix(client_side_result_list)\n",
        "        for d in Universe_list:\n",
        "            freq_vect[d] = self.Server_Side(Sketch_Matrix,d,length) \n",
        "        return freq_vect\n",
        "\n",
        "def Client_SFP(d,CMS_class_main, CMS_class_not):\n",
        "    '''d is a tuple in our example, so for converting it to a string, we are doing this d[0]*self.max+d[1] and then make it a string.'''\n",
        "    l = np.random.randint(2)\n",
        "    d =  str(d[0]*90+d[1])\n",
        "    if len(d)<4:\n",
        "        pad = 4-len(d)\n",
        "        for i in range(pad):\n",
        "            d+='0'\n",
        "    output256 = hashlib.sha256(d.encode('utf-8')).hexdigest()#h(s)\n",
        "    r = output256 + d[2*l:2*l+2]\n",
        "    return (CMS_class_not.Client_Side(r), CMS_class_main.Client_Side(d),l,r)\n",
        "\n",
        "def splitter(string):\n",
        "    '''getting a string, it splits it into two parts, second part contains the last two characters.'''\n",
        "    return string[:-2],string[-2:]\n",
        "\n",
        "def Server_SFP(M,M1,M2,T):\n",
        "    '''It gets the output from client frequency cunter, which is basically three frequency histogram dictionaries, then it does the next steps.'''\n",
        "    Q1=set(dict(sorted(M1.items(), key = itemgetter(1), reverse =True)[:T]).keys())\n",
        "    Q2=set(dict(sorted(M2.items(), key = itemgetter(1), reverse =True)[:T]).keys())\n",
        "    Q1_dict={}\n",
        "    Q2_dict={}\n",
        "    for elt in Q1:\n",
        "        word,val = splitter(elt)\n",
        "        Q1_dict[word]=val\n",
        "    for elt in Q2:\n",
        "        word,val=splitter(elt)\n",
        "        Q2_dict[word]=val \n",
        "    #will find the intersection of Q1 and Q2\n",
        "    new_string_set = set()\n",
        "    for word in Q1_dict:\n",
        "        if word in Q2_dict:\n",
        "            add_string = Q1_dict[word]+Q2_dict[word]\n",
        "            new_string_set.add(add_string)\n",
        "    final_freq_dict ={}\n",
        "    for elt in new_string_set:\n",
        "        final_freq_dict[elt]=M[elt]\n",
        "    return final_freq_dict\n",
        "\n",
        "def Client_frequency_counter_on_average(run_number,D_s,Universe_list):#this part is controlled by client side too\n",
        "    '''cal'''\n",
        "    b_freq_cum={d:0 for d in Universe_list}\n",
        "    Universe_list1=[]\n",
        "    for i in range(run_number):\n",
        "        big_elt_set=[]\n",
        "        CMS_Class_Main =  Differential_Privacy_CMS_with_SFP(100,100,5,90)\n",
        "        CMS_Class_not = Differential_Privacy_CMS_with_SFP(100,100,5,90)\n",
        "        for elt in D_s:\n",
        "            val = Client_SFP(elt,CMS_Class_Main,CMS_Class_not)\n",
        "            big_elt_set.append(val)\n",
        "        beta_data=[]\n",
        "        alpha_list1=[]\n",
        "        alpha_list2=[]\n",
        "        for elt in big_elt_set:\n",
        "            beta_data.append(elt[1])\n",
        "            Universe_list1.append(elt[3])\n",
        "            if elt[2]==0:\n",
        "                alpha_list1.append(elt[0])\n",
        "            else:\n",
        "                alpha_list2.append(elt[0])\n",
        "        a_freq_cum1={d:0 for d in Universe_list1}\n",
        "        a_freq_cum2={d:0 for d in Universe_list1}\n",
        "        #created lists of client side.\n",
        "        b_freq_dict = CMS_Class_Main.Count_Mean_Sketch(beta_data,Universe_list)\n",
        "        a_freq_dict1 = CMS_Class_not.Count_Mean_Sketch(alpha_list1,Universe_list1)\n",
        "        a_freq_dict2 = CMS_Class_not.Count_Mean_Sketch(alpha_list2, Universe_list1)\n",
        "        for d in b_freq_dict:\n",
        "            b_freq_cum[d]=(i*b_freq_cum[d]+b_freq_dict[d])/(i+1)   \n",
        "        for d in Universe_list1:\n",
        "            a_freq_cum1[d]=(i*a_freq_cum1[d]+a_freq_dict1[d])/(i+1)\n",
        "            a_freq_cum2[d]=(i*a_freq_cum2[d]+a_freq_dict2[d])/(i+1)\n",
        "    return b_freq_cum, a_freq_cum1, a_freq_cum2\n",
        "\n",
        "def Sequence_Fragment_Puzzle(run_number,D_s,T,Universe_list):\n",
        "    '''Main driver code of sequence fragment puzzle.'''\n",
        "    M, M1, M2 = Client_frequency_counter_on_average(run_number,D_s,Universe_list)\n",
        "    return Server_SFP(M, M1, M2, T)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG_lacFLADxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plan: we need to call client side multiple times becuase else we don't get different distribution. For one \n",
        "#call of client side, we compute sketch matrix and do frequency count. but the client side is being called from client SFP.\n",
        "#so in order to average like something, we need to call client side multiple times too. And the client side algo is being callled from driver \n",
        "#SFP. To sum up, we need to do this process multiple times and take the average to get a good count-\n",
        "#1.Call Client SFP\n",
        "#2.Push this output to the Sketch CMS matrix\n",
        "#3.Push Sketch CMS Matrix to the server for frequency histogram\n",
        "#4.Continue this process multiple times  or repeat this process multiple times(So basically the client device does this query multiple times)\n",
        "#to get a better frequency estimation)\n",
        "#5. Then send this frequency histograms to the server SFP to do further calculation."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWafdKcyZrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true_path = [(15, 7),\n",
        " (15, 6),\n",
        " (15, 7),\n",
        " (14, 7),\n",
        " (14, 6),\n",
        " (13, 6),\n",
        " (13, 5),\n",
        " (14, 5),\n",
        " (15, 5),\n",
        " (14, 5),\n",
        " (13, 5),\n",
        " (12, 5),\n",
        " (12, 6),\n",
        " (12, 5),\n",
        " (12, 6),\n",
        " (13, 6),\n",
        " (12, 6),\n",
        " (12, 5),\n",
        " (12, 6),\n",
        " (12, 5),\n",
        " (12, 4),\n",
        " (12, 3),\n",
        " (13, 3),\n",
        " (13, 2),\n",
        " (12, 2),\n",
        " (12, 1),\n",
        " (12, 0),\n",
        " (11, 0),\n",
        " (10, 0),\n",
        " (9, 0),\n",
        " (8, 0),\n",
        " (9, 0),\n",
        " (9, 1),\n",
        " (10, 1),\n",
        " (9, 1),\n",
        " (10, 1),\n",
        " (11, 1),\n",
        " (12, 1),\n",
        " (13, 1),\n",
        " (14, 1),\n",
        " (13, 1),\n",
        " (12, 1),\n",
        " (12, 2),\n",
        " (12, 3),\n",
        " (11, 3),\n",
        " (11, 2),\n",
        " (12, 2),\n",
        " (13, 2),\n",
        " (12, 2),\n",
        " (11, 2),\n",
        " (10, 2),\n",
        " (9, 2),\n",
        " (10, 2),\n",
        " (11, 2),\n",
        " (11, 3),\n",
        " (10, 3),\n",
        " (10, 4),\n",
        " (10, 5),\n",
        " (10, 6),\n",
        " (10, 7),\n",
        " (9, 7),\n",
        " (9, 8),\n",
        " (8, 8),\n",
        " (7, 8),\n",
        " (7, 9),\n",
        " (7, 8),\n",
        " (6, 8),\n",
        " (6, 9),\n",
        " (6, 10),\n",
        " (5, 10),\n",
        " (5, 9),\n",
        " (6, 9),\n",
        " (6, 10),\n",
        " (6, 11),\n",
        " (5, 11),\n",
        " (6, 11),\n",
        " (6, 10),\n",
        " (5, 10),\n",
        " (4, 10),\n",
        " (4, 9),\n",
        " (5, 9),\n",
        " (5, 8),\n",
        " (4, 8),\n",
        " (4, 9),\n",
        " (4, 8),\n",
        " (4, 7),\n",
        " (5, 7),\n",
        " (5, 8),\n",
        " (5, 9),\n",
        " (6, 9),\n",
        " (7, 9),\n",
        " (6, 9),\n",
        " (7, 9),\n",
        " (6, 9),\n",
        " (5, 9),\n",
        " (4, 9),\n",
        " (5, 9),\n",
        " (5, 8),\n",
        " (4, 8),\n",
        " (3, 8),\n",
        " (2, 8),\n",
        " (1, 8),\n",
        " (2, 8),\n",
        " (2, 9),\n",
        " (1, 9),\n",
        " (2, 9),\n",
        " (2, 10),\n",
        " (3, 10),\n",
        " (2, 10),\n",
        " (2, 11),\n",
        " (3, 11),\n",
        " (2, 11),\n",
        " (1, 11),\n",
        " (2, 11),\n",
        " (1, 11),\n",
        " (1, 10),\n",
        " (1, 9),\n",
        " (2, 9),\n",
        " (1, 9),\n",
        " (2, 9),\n",
        " (3, 9),\n",
        " (2, 9),\n",
        " (2, 8),\n",
        " (1, 8),\n",
        " (1, 9),\n",
        " (2, 9),\n",
        " (1, 9),\n",
        " (1, 10),\n",
        " (1, 9),\n",
        " (1, 10),\n",
        " (1, 11),\n",
        " (1, 12),\n",
        " (1, 11),\n",
        " (2, 11),\n",
        " (1, 11),\n",
        " (0, 11),\n",
        " (1, 11),\n",
        " (1, 12),\n",
        " (1, 11),\n",
        " (1, 10),\n",
        " (1, 9),\n",
        " (2, 9),\n",
        " (2, 10),\n",
        " (2, 11),\n",
        " (2, 12),\n",
        " (2, 11),\n",
        " (3, 11),\n",
        " (3, 10),\n",
        " (3, 9),\n",
        " (2, 9),\n",
        " (2, 10),\n",
        " (1, 10),\n",
        " (1, 9),\n",
        " (2, 9),\n",
        " (2, 10),\n",
        " (2, 11),\n",
        " (3, 11),\n",
        " (3, 10),\n",
        " (4, 10),\n",
        " (4, 9),\n",
        " (3, 9),\n",
        " (4, 9),\n",
        " (4, 8),\n",
        " (5, 8),\n",
        " (4, 8),\n",
        " (5, 8),\n",
        " (4, 8),\n",
        " (4, 9),\n",
        " (4, 8),\n",
        " (5, 8),\n",
        " (5, 7),\n",
        " (5, 6),\n",
        " (5, 5),\n",
        " (5, 4),\n",
        " (5, 3),\n",
        " (5, 4),\n",
        " (6, 4),\n",
        " (7, 4),\n",
        " (8, 4),\n",
        " (7, 4),\n",
        " (8, 4),\n",
        " (8, 3),\n",
        " (7, 3),\n",
        " (8, 3),\n",
        " (8, 2),\n",
        " (9, 2),\n",
        " (8, 2),\n",
        " (7, 2),\n",
        " (7, 3),\n",
        " (6, 3),\n",
        " (5, 3),\n",
        " (4, 3),\n",
        " (4, 2),\n",
        " (5, 2),\n",
        " (4, 2),\n",
        " (3, 2),\n",
        " (3, 1),\n",
        " (2, 1),\n",
        " (2, 0),\n",
        " (2, 1)]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXMjJHaL0zQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "universe_list = [(x,y) for x in range(20) for y in range(80)]\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofmgq0CVh4EE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def string_maker(d):\n",
        "    d =  str(d[0]*90+d[1])\n",
        "    if len(d)<4:\n",
        "        pad = 4-len(d)\n",
        "        for i in range(pad):\n",
        "            d+='0'\n",
        "    return d"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq8LgLvwhIo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Universe_list=[]\n",
        "for elt in universe_list:\n",
        "    Universe_list.append(string_maker(elt))\n",
        "    \n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASpl7QAeghi_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc4GEENM0__I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Sequence_Fragment_Puzzle(500,true_path,250,Universe_list)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}